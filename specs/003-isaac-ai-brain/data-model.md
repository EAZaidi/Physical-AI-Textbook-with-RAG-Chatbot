# Data Model: Module 3 - The AI-Robot Brain (NVIDIA Isaac)

**Feature**: 003-isaac-ai-brain
**Date**: 2025-12-08

---

## Overview

This module focuses on educational content delivery (not a traditional application with databases). The "entities" here represent conceptual data structures and ROS 2 message types that students will work with during Isaac Sim, Isaac ROS, and Nav2 tutorials.

---

## Entity 1: Isaac Sim Scene

**Description**: Photorealistic simulation environment in Universal Scene Description (USD) format containing robot, sensors, obstacles, and physics configuration.

**Key Attributes**:
- `scene_file`: File path to .usd scene (e.g., `humanoid_warehouse.usd`)
- `robot_model`: Reference to humanoid URDF from Module 2
- `sensors`: List of attached sensors (cameras, LiDAR, IMU)
  - Camera: `sensor_type: "camera"`, `resolution: [1920, 1080]`, `fov: 90`, `fps: 30`
  - LiDAR: `sensor_type: "lidar"`, `range: 30.0`, `scan_rate: 10`
- `static_obstacles`: List of objects (shelves, walls, boxes) with collision meshes
- `physics_config`:
  - `gravity: [0, 0, -9.81]`
  - `time_step: 0.0166` (60Hz)
  - `solver_iterations: 4`
- `lighting`: Dome light or directional light configuration

**Relationships**:
- Contains 1 humanoid robot (from Module 2 URDF)
- Contains 0+ sensors attached to robot links
- Contains 0+ static obstacles (USD prims)

**Validation Rules**:
- Scene must contain ground plane with physics material
- Robot spawn pose must be collision-free
- All sensors must have valid ROS 2 topic names

**State Transitions**: N/A (static scene description)

**ROS 2 Representation**: Published as TF transforms, sensor topics (sensor_msgs/Image, sensor_msgs/PointCloud2)

---

## Entity 2: Sensor Data Stream

**Description**: Real-time data published from Isaac Sim sensors to ROS 2 topics for perception processing.

**Key Attributes**:
- `topic_name`: ROS 2 topic (e.g., `/camera/left/image_raw`)
- `message_type`: ROS 2 message type (e.g., `sensor_msgs/Image`, `sensor_msgs/PointCloud2`)
- `frame_id`: TF frame (e.g., `camera_left_optical_frame`)
- `publish_rate`: Frequency in Hz (e.g., 30 Hz for camera, 10 Hz for LiDAR)
- `data_payload`:
  - For Image: `width`, `height`, `encoding` (rgb8, bgr8), `data` (bytes)
  - For PointCloud2: `width`, `height`, `fields` (x, y, z, rgb), `data` (bytes)
  - For CameraInfo: `K` (3x3 intrinsic matrix), `D` (distortion coefficients)

**Relationships**:
- Produced by Isaac Sim Scene sensors
- Consumed by Isaac ROS VSLAM nodes

**Validation Rules**:
- Topic names must match ROS 2 naming conventions
- Camera topics must have corresponding CameraInfo
- Timestamps must be synchronized (use `use_sim_time: true`)

**State Transitions**:
1. `idle`: Sensor exists but Isaac Sim not running
2. `active`: Sensor publishing data
3. `paused`: Simulation paused (no new data)

**ROS 2 Representation**:
- `sensor_msgs/Image` (RGB, depth)
- `sensor_msgs/CameraInfo` (camera calibration)
- `sensor_msgs/PointCloud2` (LiDAR)
- `sensor_msgs/Imu` (inertial measurement)

---

## Entity 3: VSLAM Map

**Description**: 3D point cloud map and pose graph generated by Isaac ROS Visual SLAM from stereo camera data.

**Key Attributes**:
- `map_points`: 3D point cloud (sensor_msgs/PointCloud2)
  - Each point: `x, y, z` coordinates in map frame
  - Color: `rgb` (optional, from image texture)
  - Map frame: `map` or `odom`
- `pose_graph`: List of keyframe poses
  - Each keyframe: `position (x, y, z)`, `orientation (quaternion)`, `timestamp`
  - Edges: Loop closure constraints
- `current_pose`: Latest robot pose estimate (geometry_msgs/PoseWithCovarianceStamped)
  - `position (x, y, z)`, `orientation (quaternion)`
  - `covariance`: 6x6 matrix (uncertainty in x, y, z, roll, pitch, yaw)
- `tracking_status`: `TRACKING`, `LOST`, `INITIALIZING`

**Relationships**:
- Built from Sensor Data Streams (stereo camera images)
- Consumed by Occupancy Grid generation (for Nav2)

**Validation Rules**:
- Map must have >100 points for reliable localization
- Pose covariance must be <0.1m in x, y, z for accurate navigation
- Loop closures detected when robot revisits area (drift correction)

**State Transitions**:
1. `initializing`: Waiting for sufficient visual features
2. `tracking`: Actively localizing and mapping
3. `lost`: Feature tracking failed (low texture or fast motion)

**ROS 2 Representation**:
- `/visual_slam/tracking/odometry` (nav_msgs/Odometry)
- `/visual_slam/vis/map_points` (sensor_msgs/PointCloud2)
- `/visual_slam/tracking/vo_pose_covariance` (geometry_msgs/PoseWithCovarianceStamped)

---

## Entity 4: Occupancy Grid

**Description**: 2D costmap representing navigable space, obstacles, and inflation zones for Nav2 path planning.

**Key Attributes**:
- `resolution`: Grid cell size in meters (e.g., 0.05m = 5cm cells)
- `width`, `height`: Grid dimensions in cells
- `origin`: Map origin pose (x, y, theta)
- `data`: 1D array of cost values
  - `0`: Free space (navigable)
  - `100`: Lethal obstacle (collision)
  - `1-99`: Inflation cost (scaled distance to obstacles)
  - `-1`: Unknown space (not explored)
- `layers`:
  - `static_layer`: Fixed obstacles from scene
  - `inflation_layer`: Cost gradient around obstacles
  - `obstacle_layer`: Dynamic obstacles (optional)

**Relationships**:
- Generated from VSLAM Map (point cloud → 2D projection)
- OR generated from LiDAR scans directly
- Consumed by Nav2 global and local planners

**Validation Rules**:
- Resolution must match planner requirements (typical: 0.05m)
- Inflation radius must be >robot radius (ensure clearance)
- Unknown cells must be treated as obstacles (conservative)

**State Transitions**: Updated continuously as robot explores (SLAM) or statically loaded from map file

**ROS 2 Representation**:
- `nav_msgs/OccupancyGrid` published on `/map` or `/global_costmap/costmap`
- Topic: `/local_costmap/costmap` for local planning window

---

## Entity 5: Nav2 Behavior Tree

**Description**: Hierarchical state machine controlling navigation behaviors (move to goal, recovery, obstacle avoidance).

**Key Attributes**:
- `tree_structure`: XML or YAML definition
  - Root: `NavigateToPose`
  - Children: `ComputePathToPose`, `FollowPath`, `RecoveryNode`
- `current_state`: Active behavior node (e.g., `FollowPath`, `Spin`, `BackUp`)
- `blackboard`: Shared data storage
  - `goal`: Target pose (geometry_msgs/PoseStamped)
  - `path`: Computed path (nav_msgs/Path)
  - `error_code`: Failure reason (e.g., `PLANNER_TIMEOUT`, `CONTROLLER_FAILED`)

**Relationships**:
- Reads from Occupancy Grid (for planning)
- Reads current robot pose from VSLAM Map
- Sends velocity commands to robot controller

**Validation Rules**:
- Tree must have `NavigateToPose` as root action
- Recovery behaviors must be defined (spin, back up, wait)
- Timeout values must be reasonable (e.g., 30s for planning)

**State Transitions**:
1. `idle`: No goal active
2. `planning`: Computing path to goal
3. `following`: Executing path
4. `recovering`: Handling failure (stuck, lost)
5. `succeeded`: Goal reached (within tolerance)
6. `aborted`: Navigation failed (unreachable goal)

**ROS 2 Representation**:
- Configured via YAML file (`nav2_params_bipedal.yaml`)
- Status published on `/behavior_tree_log` (visualization)

---

## Entity 6: Navigation Goal

**Description**: Target pose (position + orientation) commanded to Nav2, either via RViz2 GUI or programmatic API.

**Key Attributes**:
- `pose`:
  - `position (x, y, z)`: Target location in map frame
  - `orientation (quaternion)`: Desired robot heading
- `frame_id`: Reference frame (typically `map`)
- `tolerance`:
  - `xy_goal_tolerance`: 0.1m (acceptable position error)
  - `yaw_goal_tolerance`: 0.1 rad (~6 degrees, acceptable heading error)
- `status`: `PENDING`, `ACTIVE`, `SUCCEEDED`, `ABORTED`

**Relationships**:
- Sent to Nav2 Behavior Tree
- Checked against Occupancy Grid (must be in free space)

**Validation Rules**:
- Goal must be within map bounds
- Goal must not be in lethal obstacle cell (cost=100)
- Goal must be reachable (no isolated islands)

**State Transitions**:
1. `pending`: Goal received, not yet processing
2. `active`: Nav2 planning/following path
3. `succeeded`: Robot within tolerance of goal
4. `aborted`: Goal unreachable or timeout

**ROS 2 Representation**:
- Action: `nav2_msgs/action/NavigateToPose`
- Sent via: `ros2 action send_goal` or RViz2 "2D Goal Pose" button

---

## Entity 7: Docker Container (Isaac ROS Environment)

**Description**: Isolated reproducible environment with Isaac ROS dependencies (CUDA, TensorRT, ROS 2 packages).

**Key Attributes**:
- `base_image`: `nvcr.io/nvidia/isaac-ros:humble-ros2_humble_20231122`
- `gpu_support`: Requires NVIDIA Container Toolkit
- `ros_packages`: isaac_ros_visual_slam, isaac_ros_common, isaac_ros_nvblox
- `system_libs`: CUDA 11.8, TensorRT 8.5, cuDNN 8.9
- `volumes`:
  - `/workspaces/isaac_ros-dev`: Mounted workspace
  - `/tmp/.X11-unix`: X11 socket for GUI (RViz2)
- `network_mode`: `host` (for ROS 2 DDS discovery) or bridge with configured DDS

**Relationships**:
- Receives Sensor Data Streams from Isaac Sim (external)
- Runs Isaac ROS VSLAM processing
- Publishes VSLAM Map and odometry

**Validation Rules**:
- NVIDIA GPU must be accessible (`nvidia-smi` works inside container)
- ROS 2 topics must be visible between container and host (`ROS_DOMAIN_ID` match)
- Container build must complete in <30 minutes

**State Transitions**:
1. `building`: Docker image being created
2. `running`: Container active, ROS 2 nodes launched
3. `stopped`: Container exited

**ROS 2 Representation**: N/A (infrastructure, not a ROS 2 entity)

---

## Entity Relationships Diagram

```text
Isaac Sim Scene
    ↓ (publishes)
Sensor Data Stream
    ↓ (consumed by)
Docker Container (Isaac ROS)
    ↓ (generates)
VSLAM Map
    ↓ (converts to)
Occupancy Grid
    ↓ (used by)
Nav2 Behavior Tree
    ↑ (receives)
Navigation Goal
    ↓ (executes)
Robot Motion
```

---

## Notes for Implementation

- All entities are conceptual for educational purposes; no database persistence required
- ROS 2 message types are authoritative references (see http://docs.ros.org/en/humble/)
- Isaac Sim scenes (.usd files) are binary assets, not code (students download and import)
- Docker configurations ensure reproducibility but are optional (fallback: native installation)

---

**Data Model Complete**: Ready for Phase 1 contract generation (YAML configs, launch files).
